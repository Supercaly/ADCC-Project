% !TEX root = ice2022.tex

Several paradigms for parallel and distributed computing have been theorised and developed so far, and all of them differ either by the communication mechanism they use or by the level of abstraction they offer to the programmers. Among these, we can list those based on \emph{message passing} like remote procedure call (RPC), remote method invocation (RMI), distributed objects, message passing interface MPI; and those based on \emph{shared memory} like software transactional memory, tuple space~\cite{Gelernter85}, shared objects and  openMP~\cite{Mattson03}. Among these, the one which is less used is tuple space. Despite its simplicity, the lack of a reference implementation for this paradigm has prevented its wide spreading~\cite{BuravlevNM18}.


Tuple space is an abstraction of shared and distributed memory, made popular by the Linda programming language~\cite{Gelernter85}. Its idea is very simple and intuitive: agents communicate and synchonise each other by writing and reading data from a shared repository. This is also referred as the black-board metaphor. 
It consists of a (shared) repository of tuples (e.g., vectors of values) where agents can read, write or withdrawn (i.e., consume) tuples in an atomic way. 
The operations of reading and withdrawing use  \emph{pattern-matching} to access to the repository.
 These are also blocking operations:  if there are no tuples matching a particular pattern, then the agent performing the operation is blocked until a new matching tuple is produced (by another agent). The simplicity of this coordination model makes very intuitive and simple to implement various syncrhonisation mechanisms such as semaphores, synchronisation barriers, randezvous and so on (cf.,~\cite{Doberkat00b} Chapter 4). To give the general idea behind tuple space, let us consider the example depicted in Figure~\ref{fig:example}, which represents an execution of the following processes\footnote{Sometime we will refer to a process as an agent and viceversa.} $A$ and $B$: 
 \input{example.tex}
 \noindent In the code above, process $A$ produces, via the out operation, a tuple of the form $\tuple{\str{sum},2,3}$ indicating the fact it wants
 another process to perform the task $\str{sum}$. Process $B$ consumes a tuple which satisfy the pattern $\tuple{\str{sum},x,y}$. This pattern will match any tuple with 3 elements 
  whose first element is the exact string
 $\str{sum}$. Moreover, it  binds the second and third element of such a tuple to the variables $x$ and $y$, respectively. To compute the sum, process $B$ simply emits a tuple of the form $\tuple{\str{res},x+y}$. Let us note that what is shown in Figure~\ref{fig:example} is just one possible execution, since the pattern used by process $B$ at line
 $4$ could also match the tuple $\tuple{\str{sum},4,7}$. Also, the Linda model provides time and  space decoupling~\cite{EugsterFGK03}, meaning that a tuple can survive to its producer. This is rendered in Figure~\ref{fig:example} by the tuple $\tuple{\str{sum},4,7}$ which is already present in the tuple space during the execution of $A$ and $B$. The simplicity of the model comes at the cost of inefficiency when implementing it: a tuple space can be distributed, and hence one has to deal with replicas and consistency, and more importantly in and out operation are atomic. In the last decades there have been several implementation of tuple space, but all of them suffer from performance issues~\cite{BuravlevNM18}.
 
 \begin{figure}
\centering
 	\includegraphics[scale=.2]{tuple_space}
	\label{fig:example}
	\caption{Example of tuple space}
 \end{figure}
 
  In this paper we take a detour on what has been done so far about tuple space implementations, by using a language which is designed to work with distributed systems and comes with an ecosystem for failure handling: Erlang. The structure of the paper is as follows: in section~\ref{sec:erlang} we introduce Erlang, its concurrency model and the OTP ecosystem. %Section~\ref{sec:impl} is about our implementation \cdots
